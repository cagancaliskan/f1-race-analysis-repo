from pyspark.sql import SparkSession

# Apache Spark oturumunu baÅŸlat
spark = SparkSession.builder.appName("F1RaceAnalysis").getOrCreate()

# CSV verilerini yÃ¼kle
pit_stops_df = spark.read.csv("data/pit_stops_2023_Monza.csv", header=True, inferSchema=True)
fastest_laps_df = spark.read.csv("data/fastest_laps_2023_Monza.csv", header=True, inferSchema=True)
weather_df = spark.read.csv("data/weather_2023_Monza.csv", header=True, inferSchema=True)

# âš¡ En hÄ±zlÄ± tur atan sÃ¼rÃ¼cÃ¼leri analiz et
fastest_laps_df.groupBy("driver").avg("lap_time").orderBy("avg(lap_time)").show()

# â˜ï¸ Hava durumu ve pit stop iliÅŸkisi
weather_df.join(pit_stops_df, "session_time").groupBy("weather_condition").avg("pit_stop_time").show()

# ğŸ”¥ TakÄ±mlara gÃ¶re ortalama pit stop sÃ¼releri
pit_stops_df.groupBy("team").avg("pit_stop_time").orderBy("avg(pit_stop_time)").show()

print("âœ… Apache Spark analizleri tamamlandÄ±!")
